{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f996c7",
   "metadata": {},
   "source": [
    "# Tutorial: Predicting the Decade of a Movie from Its Title\n",
    "\n",
    "### Goal: Use machine learning (NLP) to predict the decade a movie was released in (e.g., 1950s, 1980s, 2000s) based only on the words in the title.\n",
    "\n",
    "#### 1. Turn messy text into usable ML features with TF-IDF\n",
    "#### 2. Train/test split and evaluate a model\n",
    "#### 3. Interpret what words are predictive of different decades\n",
    "#### 4. Build a simple function to make predictions on new titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c5c3e9",
   "metadata": {},
   "source": [
    "## Part 1. Setup & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a973b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1', '2003', 'Dinosaur Planet'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Isle of Man TT 2004 Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>The Rise and Fall of ECW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Sick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Year                         Title\n",
       "0   2  2004.0    Isle of Man TT 2004 Review\n",
       "1   3  1997.0                     Character\n",
       "2   4  1994.0  Paula Abdul's Get Up & Dance\n",
       "3   5  2004.0      The Rise and Fall of ECW\n",
       "4   6  1997.0                          Sick"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"movie_titles.csv\", encoding=\"latin1\", on_bad_lines=\"skip\")\n",
    "df.head()\n",
    "print(df.columns)\n",
    "#Rename the columns\n",
    "df.columns = [\"ID\", \"Year\", \"Title\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the unneccessary ID column\n",
    "df = df.drop(columns=[\"ID\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efeaac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gotta take care of NA values\n",
    "# imputation\n",
    "df.isnull().sum()\n",
    "df.fillna(df['Year'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f337c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>Isle of Man TT 2004 Review</td>\n",
       "      <td>2000s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997</td>\n",
       "      <td>Character</td>\n",
       "      <td>1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1994</td>\n",
       "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
       "      <td>1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>The Rise and Fall of ECW</td>\n",
       "      <td>2000s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997</td>\n",
       "      <td>Sick</td>\n",
       "      <td>1990s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                         Title Decade\n",
       "0  2004    Isle of Man TT 2004 Review  2000s\n",
       "1  1997                     Character  1990s\n",
       "2  1994  Paula Abdul's Get Up & Dance  1990s\n",
       "3  2004      The Rise and Fall of ECW  2000s\n",
       "4  1997                          Sick  1990s"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the target variable 'Decade'\n",
    "df['Year'] = df['Year'].astype('Int64')\n",
    "df['Decade'] = ((df['Year'] // 10) * 10).astype('int').astype('str') + 's'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f113aa",
   "metadata": {},
   "source": [
    "## Part 2. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d77f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Features (X) = movie titles\n",
    "X = df['Title']\n",
    "\n",
    "# Target (y) = decade\n",
    "Y = df['Decade']\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "# Convert titles to numeric features using TF-IDF - so that ML models can understand\n",
    "# TF-IDF = Term Frequency â€“ Inverse Document Frequency. It reflects how important a word is to a document in a collection.\n",
    "vectorizer = TfidfVectorizer(stop_words= 'english')\n",
    "# fit: learns the vocabulary of all unique words in the training set\n",
    "# transform: converts each title into a numeric vector\n",
    "# X_train_tfidf is a sparse matrix of shape [num_titles, num_words]\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# essentially each row = one title, each column = one word from the training vocabulary, each cell = how important that word is in that title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0230b88",
   "metadata": {},
   "source": [
    "## Part 3. Train a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ad377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       1910s       1.00      0.33      0.50         3\n",
      "       1920s       0.00      0.00      0.00        17\n",
      "       1930s       0.50      0.02      0.04        44\n",
      "       1940s       0.00      0.00      0.00        75\n",
      "       1950s       0.00      0.00      0.00       100\n",
      "       1960s       0.55      0.09      0.16       196\n",
      "       1970s       0.44      0.04      0.08       266\n",
      "       1980s       0.32      0.09      0.14       411\n",
      "       1990s       0.37      0.35      0.36      1021\n",
      "       2000s       0.43      0.75      0.55      1354\n",
      "\n",
      "    accuracy                           0.41      3487\n",
      "   macro avg       0.36      0.17      0.18      3487\n",
      "weighted avg       0.39      0.41      0.35      3487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# We've talked about this before but remember these tips for interpreting the classification report:\n",
    "# precision: Of the titles predicted as being in this decade, how many were correct? High precision = few false positives.\n",
    "# recall: Of the titles that actually belong to this decade, how many did the model catch? High recall = few false negatives.\n",
    "# f1-score: Harmonic mean of precision & recall (balances the two).\n",
    "# support: Number of test samples in that class (how many actual titles from that decade were in your test set).\n",
    "\n",
    "\n",
    "# Accuracy: 0.41 (41%): the model is correct about 4 times out of 10. This is better than random guessing, but still weak for a classifier.\n",
    "# Macro avg (0.18 f1-score): the model is performing very poorly across most decades, especially older ones.\n",
    "# Weighted avg (0.35 f1-score): dominated by the bigger classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f421eb1",
   "metadata": {},
   "source": [
    "## Part 4. Interpret the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "147632a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words for 1890s: ['bonus' 'material' 'love' 'series' 'vol' 'live' 'season' 'brothers'\n",
      " 'films' 'lumiere']\n",
      "Top words for 1900s: ['love' 'series' 'vol' 'live' 'season' 'years' 'griffith' 'discovery'\n",
      " '1913' '1909']\n",
      "Top words for 1910s: ['cook' 'felix' 'slapstick' 'intolerance' 'cabiria' 'comedies' 'essanay'\n",
      " 'mutuals' 'vol' 'chaplin']\n",
      "Top words for 1920s: ['faust' 'sparrows' 'cocoanuts' 'piccadilly' 'gold' 'storm' 'rush' 'ages'\n",
      " 'silent' 'sheik']\n",
      "Top words for 1930s: ['hardy' 'rogers' 'trail' 'angel' 'frankenstein' 'little' 'collection'\n",
      " 'feathers' 'fields' 'stooges']\n",
      "Top words for 1940s: ['rebecca' 'chan' 'val' 'lewton' 'stooges' 'sierra' 'bataan' 'fighting'\n",
      " 'sherlock' 'holmes']\n",
      "Top words for 1950s: ['beat' 'kiss' 'bonanza' 'earth' 'ikiru' 'outer' 'costello' 'abbott'\n",
      " 'river' 'lucy']\n",
      "Top words for 1960s: ['andy' 'avengers' 'dyke' 'dr' 'doctor' 'griffith' 'flintstones' 'zone'\n",
      " 'vol' 'twilight']\n",
      "Top words for 1970s: ['female' 'fingers' 'happening' 'cheerleaders' 'season' 'sanford'\n",
      " 'connection' 'satan' 'muppet' 'mash']\n",
      "Top words for 1980s: ['duty' 'brewster' 'nature' 'mysteries' 'unsolved' 'police' 'cheers'\n",
      " 'dwarf' '13th' 'ii']\n",
      "Top words for 1990s: ['mystery' 'highlander' 'fiction' 'slayers' 'cadfael' 'babylon' 'athletes'\n",
      " 'imax' 'sharpe' 'morse']\n",
      "Top words for 2000s: ['yoga' 'ultimate' 'tour' 'discovering' 'nba' 'inside' 'live' 'lynley'\n",
      " '2004' 'wwe']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get top words that influence predictions for each decade\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "for decade in model.classes_:\n",
    "    coef = model.coef_[model.classes_.tolist().index(decade)]\n",
    "    top10 = np.argsort(coef)[-10:]\n",
    "    print(f\"Top words for {decade}: {feature_names[top10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c493b",
   "metadata": {},
   "source": [
    "## Part 5. Try It Yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7808f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990s\n",
      "2000s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_decade(title):\n",
    "    vec = vectorizer.transform([title])\n",
    "    return model.predict(vec)[0]\n",
    "\n",
    "print(predict_decade(\"The Return of the King\"))\n",
    "print(predict_decade(\"Cowboys of the Dusty Trail\"))\n",
    "\n",
    "\n",
    "# Takes a raw title string,\n",
    "# Converts it into numbers using your TF-IDF vocabulary,\n",
    "# Asks your trained model which decade it thinks it belongs to,\n",
    "# Returns that decade as a single value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
